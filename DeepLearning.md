
# Deeep learning

**内部表現**: 観測したデータ(事実)から本質的な情報を抽出したもの  

### パターン認識  
入力から特徴ベクトルを抽出しベクトルを識別気にかけてクラス分けする。  
ベクトルを抽出するときどれだけ少数の変数で抽出できるかが重要->**次元削減**  
観測データに潜在的な構造があると次元削減がやりやすくなる  

##### 例
```
# input
- みかん
- いちご
- メロン
- すいか
- りんご

# 特徴
[ 野菜:0 フルーツX:1, 赤:0 橙:1 緑:2, 仁果類:0 核果類:1 殻果類:2 柑橘類:3 その他(野菜):4 ]

# 特徴ベクレル化
- みかん -> [ 1, 1, 3]
- いちご -> [ 0, 0, 4]
- メロン -> [ 0, 2, 4]
- すいか -> [ 0, 2, 4]
- りんご -> [ 1, 0, 0]
```


**醜いあひるの子の定理**:  
> 醜いアヒルの子と普通のアヒルの子、すなわち、白鳥の子とアヒルの子とは、   
> 似通った2羽のアヒルの子が似ているのと同じ程度に似ている  
  
**ノーフリーランチ定理**: 
> コスト関数の極値を探索するあらゆるアルゴリズムは、  
> 全ての可能なコスト関数に適用した結果を平均すると同じ性能となる
  
**全てのタスクに対して優れている万能なアルゴリズムは存在しない**  
  
**表現学習**:  




